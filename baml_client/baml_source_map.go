// ----------------------------------------------------------------------------
//
//  Welcome to Baml! To use this generated code, please run the following:
//
//  $ go get github.com/boundaryml/baml
//
// ----------------------------------------------------------------------------

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ go install github.com/boundaryml/baml/baml-cli

package baml_client

var file_map = map[string]string{

	"analyze.baml":    "class Finding {\n  ruleId string @description(\"The policy name this finding relates to\")\n  level string @description(\"One of: error, warning, note, none\")\n  message string @description(\"Concise description of the issue\")\n  filePath string @description(\"Path to the file containing the issue\")\n  startLine int @description(\"Line number where the issue starts\")\n  endLine int @description(\"Line number where the issue ends\")\n  recommendation string @description(\"Suggested fix or action\")\n  explanation string @description(\"Longer reasoning about why this is an issue\")\n  confidence float @description(\"0.0 to 1.0, how confident you are in this finding\")\n}\n\nfunction AnalyzeCode(code: string, policies: string, additionalContext: string) -> Finding[] {\n  client OpenRouter\n  prompt #\"\n    You are a precise code analyzer. Analyze the following code against the given policies.\n    For each policy violation found, produce a finding. If no violations are found\n    for a policy, do not produce a finding for it.\n\n    Be precise about line numbers. Be concise in messages. Be thorough in explanations.\n    Set confidence based on how certain you are â€” use lower confidence for ambiguous cases.\n\n    Only report genuine issues. Do not fabricate findings.\n\n    Policies:\n    ---\n    {{ policies }}\n    ---\n\n    {% if additionalContext %}\n    {{ additionalContext }}\n    ---\n    {% endif %}\n\n    Code:\n    ---\n    {{ code }}\n    ---\n\n    {{ ctx.output_format }}\n  \"#\n}\n",
	"clients.baml":    "// OpenRouter client for gavel analysis\nclient<llm> OpenRouter {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url \"https://openrouter.ai/api/v1\"\n    api_key env.OPENROUTER_API_KEY\n    model \"anthropic/claude-sonnet-4\"\n  }\n}\n\n// Ollama client for local LLM analysis\nclient<llm> Ollama {\n  provider \"openai-generic\"\n  retry_policy Exponential\n  options {\n    base_url env.OLLAMA_BASE_URL\n    model env.OLLAMA_MODEL\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n",
	"generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"go\", \"rust\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"go\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.218.1\"\n\n    // 'baml-cli generate' will run this after generating go code\n    // This command will be run from within $output_dir/baml_client\n    on_generate \"gofmt -w . && goimports -w .\"\n\n    // Your Go packages name as specified in go.mod\n    // We need this to generate correct imports in the generated baml_client\n    client_package_name \"github.com/chris-regnier/gavel\"\n}\n",
}

func getBamlFiles() map[string]string {
	return file_map
}
